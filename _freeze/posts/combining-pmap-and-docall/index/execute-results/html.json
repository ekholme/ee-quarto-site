{
  "hash": "c3c7435e76a320533d4ea5d2f8de4103",
  "result": {
    "markdown": "---\ntitle: \"Combining pmap and do.call\"\ndescription: |\n  A pattern to create flexible analysis workflows\ndate: \"2022-03-15\"\ncategories: [R, programming, purrr]\npreview: img/purrr_hex.png\n---\n\n\n\nThe point of this blog post is to walk through a pattern I've started using in some of my analyses that combines `do.call()`, `purrr::pmap()`, and some wrapper functions to customize how a given analysis gets run. I'll start by demonstrating `do.call()` and `pmap()` separately, then showing how you can use them together to do some cool things. I'm not going to go super in-depth on either `do.call()` or `pmap()`, so it might be worthwhile to look into some of the documentation for those functions separately.\n\nAlso -- I'm going to use the [`{palmerpenguins}`](https://allisonhorst.github.io/palmerpenguins/) data here to illustrate this workflow. And, like, as is typically the case with toy data, the point here isn't to run a suite of analyses that answer meaningful questions about this data, but rather to demonstrate how to combine these functions in a way that could help you answer meaningful questions for your own data.\n\nWith all of that said, onward and upward!\n\n# Setup\n\nTo start, let's load the packages we'll need.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n```\n:::\n\n\n\nLet's also take a quick peeksie at the penguins data, although the content of the data isn't terrible important here.\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(penguins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n```\n:::\n:::\n\n\n\nCool cool. Now, let's assume we want to analyze this penguins data. Let's say we want to estimate a mean, a correlation coefficient, and fit a linear regression, and that this is our workflow (n.b. again that this probably shouldn't be your *actual* workflow when you analyze data).\n\nLet's say we want to get the mean body mass -- this is easy for us.\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(penguins$body_mass_g, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4201.754\n```\n:::\n:::\n\n\n\nAnother way we can do the exact same thing is with `do.call()`. `do.call()` has a \"what\" argument, to which you provide the function you want to call (or the character string name of the function), and an \"args\" argument, where you list the arguments to pass to \"what\". It has some other arguments, too, but I'm going to ignore those here. So, the call below does the exact same thing we did previously:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndo.call(what = \"mean\", args = list(penguins$body_mass_g, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4201.754\n```\n:::\n:::\n\n\n\nThe nice thing about do.call is that it's very flexible. Say we wanted to run a correlation between body mass and bill depth. We can do this by directly calling the `cor()` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# option 1:\ncor(\n    x = penguins$body_mass_g,\n    y = penguins$bill_depth_mm, \n    use = \"pairwise.complete.obs\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.4719156\n```\n:::\n:::\n\n\n\nOr we can do the exact same thing via `do.call()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# option 2\ndo.call(\"cor\",\n    args = list(\n        x = penguins$body_mass_g,\n        y = penguins$bill_depth_mm, \n        use = \"pairwise.complete.obs\"\n    )\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.4719156\n```\n:::\n:::\n\n\n\nOr say we wanted to run a linear regression with body mass regressed on bill depth and sex. Again, we can call `lm()` directly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# option 1:\nres1 <- lm(body_mass_g ~ bill_depth_mm + sex, data = penguins, na.action = \"na.omit\")\n\nbroom::glance(res1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.642         0.640  483.      296. 2.34e-74     2 -2529. 5066. 5081.\n# … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n\nOr via `do.call()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#option 2\nres2 <- do.call(\"lm\", args = list(\n    formula = body_mass_g ~ bill_depth_mm + sex,\n    data = penguins,\n    na.action = \"na.omit\"\n))\n\nbroom::glance(res2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.642         0.640  483.      296. 2.34e-74     2 -2529. 5066. 5081.\n# … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n\n## Combining with purrr::pmap ()\n\nJust based on the above, `do.call()` isn't really doing anything useful for us. It's just a slightly more verbose way to call a function. But where `do.call()` really shines is when you pair it with some iteration -- which we'll do now, via `purrr::pmap()` -- and/or some conditional logic (which we'll add later via a wrapper function). Basically it shines with you program with it, is what I'm trying to say.\n\nFor those that don't know, `purrr::pmap()` extends `purrr::map()` to allow for an arbitrary number of arguments to map over in parallel. If you're not familiar with `purrr::map()`, [Hadley's R for Data Science book](https://r4ds.had.co.nz/iteration.html) has a good chapter on it.  But anyway, let's illustrate `pmap()` by running a handful of correlations on some sample data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#generate data\na <- rnorm(100)\nb <- rnorm(100)\nd <- rnorm(100)\n\n#put data into a list\nsample_args <- list(\n    x = list(a, b, d),\n    y = list(b, d, a)\n)\n```\n:::\n\n\n\nThis gives us a list of x and y values, where the first element of `x` is `a`, the first element of `y` is `b`, etc etc. We can run a bunch of correlations -- `x[[1]]` with `y[[1]]`, `x[[2]]` with `y[[2]]` etc -- by using `pmap()` and `cor()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npmap(sample_args, ~cor(..1, ..2, use = \"pairwise.complete.obs\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 0.0467708\n\n[[2]]\n[1] 0.1479934\n\n[[3]]\n[1] -0.07458596\n```\n:::\n:::\n\n\n\nWhich can be a helpful pattern. \n\nWhat's potentially more interesting, though, is that we can also use `pmap()` in conjunction with `do.call()` to not only iterate through arguments passed to a given function (like we do with `cor()` above), but to also iterate over various functions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create a vector of function names\nfuns <- c(\"mean\", \"cor\", \"lm\")\n\n#create a list of function arguments, where each element of the list is a list of args\nfun_args <- list(\n    list(penguins$body_mass_g, na.rm = TRUE),\n    list(\n        penguins$body_mass_g, \n        penguins$bill_depth_mm, \n        use = \"pairwise.complete.obs\"\n        ),\n    list(\n        formula = body_mass_g ~ bill_depth_mm + sex,\n        data = penguins,\n        na.action = \"na.omit\"\n    )\n)\n\n#combine the function names and args into a tibble\nfun_iterator <- tibble(\n    f = funs,\n    fa = fun_args\n)\n\n#take a look at the tibble\nglimpse(fun_iterator)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 3\nColumns: 2\n$ f  <chr> \"mean\", \"cor\", \"lm\"\n$ fa <list> [<3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, 4250, 3300, 3…\n```\n:::\n:::\n\n\n\nWhat we're doing in the above code is:\n\n- creating a list of function names;\n- creating a list of function arguments (where each element of the list is a list of args);\n- binding these lists together in a tibble.\n\nThen, we can then execute all of these functions with their corresponding arguments with `do.call()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- pmap(fun_iterator, ~ do.call(..1, ..2))\n```\n:::\n\n\nWithin `do.call()`, we're passing the first column of our `fun_iterator` table to the first argument of `do.call()` (as denoted by ..1), and the second column of the tibble to the second argument of `do.call()` (as denoted by ..2). This will give us a list, `res`, where each element is the result of the function/argument combination in our `fun_iterator` tibble.\n\nTo prove it worked, let's look at the results:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#mean\nres[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4201.754\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#cor\nres[[2]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.4719156\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#lm\nbroom::glance(res[[3]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.642         0.640  483.      296. 2.34e-74     2 -2529. 5066. 5081.\n# … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n\nIn theory, you can specify an entire set of analyses ahead of time and then execute them using `pmap()` + `do.call()` if you wanted to. So let's at one way we might do that via a wrapper function.\n\n## Wrap Your Analyses\n\nThe real power of this is to write a function that wraps all of these components and allows you to run just a subset of them. And this is how I actually use this pattern in my own work. But I'll touch on some real-world applications after we go through the code below.\n\nLet's start by writing a wrapper function that has 1 argument, `include`, where `include` is a character vector of function names. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalyze_penguins <- function(include = c(\"mean\", \"cor\", \"lm\")) {\n  #some code here\n}\n```\n:::\n\n\n\nThen let's drop all of the code that we just ran into the function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalyze_penguins <- function(include = c(\"mean\", \"cor\", \"lm\")) {\n    #we already ran all of this\n    funs <- c(\"mean\", \"cor\", \"lm\")\n\n    fun_args <- list(\n        list(penguins$body_mass_g, na.rm = TRUE),\n        list(\n            penguins$body_mass_g,\n            penguins$bill_depth_mm,\n            use = \"pairwise.complete.obs\"\n        ),\n        list(\n            formula = body_mass_g ~ bill_depth_mm + sex,\n            data = penguins,\n            na.action = \"na.omit\"\n        )\n    )\n\n    fun_iterator <- tibble(\n        f = funs,\n        fa = fun_args\n    )\n}\n```\n:::\n\n\n\nAnd then we subset the `fun_iterator` tibble to only include the functions we include in the `include` argument of our wrapper function, and executed only those functions via `pmap()` + `do.call()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalyze_penguins <- function(include = c(\"mean\", \"cor\", \"lm\")) {\n    #this is all the same as previously\n    funs <- c(\"mean\", \"cor\", \"lm\")\n\n    fun_args <- list(\n        list(penguins$body_mass_g, na.rm = TRUE),\n        list(\n            penguins$body_mass_g,\n            penguins$bill_depth_mm,\n            use = \"pairwise.complete.obs\"\n        ),\n        list(\n            formula = body_mass_g ~ bill_depth_mm + sex,\n            data = penguins,\n            na.action = \"na.omit\"\n        )\n    )\n\n    fun_iterator <- tibble(\n        f = funs,\n        fa = fun_args\n    )\n\n    # filter to only a subset of these functions that we've asked for in the wrapper args\n    fun_iterator <- fun_iterator[fun_iterator$f %in% include, ]\n    \n    #execute these functions\n    pmap(fun_iterator, ~do.call(..1, ..2))\n}\n```\n:::\n\n\n\nSo, say we just wanted the mean:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalyze_penguins(\"mean\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 4201.754\n```\n:::\n:::\n\n\n\nOr just the mean and the correlation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanalyze_penguins(c(\"mean\", \"cor\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n[1] 4201.754\n\n[[2]]\n[1] -0.4719156\n```\n:::\n:::\n\n\n\nOr just the linear model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbroom::glance(analyze_penguins(\"lm\")[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.642         0.640  483.      296. 2.34e-74     2 -2529. 5066. 5081.\n# … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n\nI really like this pattern for data cleaning. I have a handful of demographic variables that I regularly work with that need to be cleaned and/or recoded, and I have some helper functions I've written to clean/recode each of them individually. But I also have a \"meta\" `recode_demographics()` function that can execute any combination of my helper functions depending on what I need for a given project. You can obviously also write your wrapper function to give you more control over the arguments to each constituent function (like by allowing you to pass in a formula to `lm()`, for instance, rather than hardcoding your formula), which can make this whole approach very flexible! It can be a bit time-consuming to write a wrapper that gives you the right level of flexibility, but if you have a set of related tasks you do frequently, I think it's worth the time to figure out.\n  \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}